{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELO DE RECOMENDACION DE PELICULAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a trabajar el modelo de Machine Learning en un Notebook, para posteriormente incluirlo en el script main.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar la Informacion\n",
    "# Función que carga los datos desde un archivo Parquet\n",
    "def cargar_datos():\n",
    "    df_data_filtrada = pd.read_parquet('../data_filtrada.parquet')\n",
    "    return df_data_filtrada\n",
    "\n",
    "#Cargo los Datos\n",
    "data_filtrada = cargar_datos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  vectorizo la información de texto\n",
    "tfidf = TfidfVectorizer(stop_words='english')    #Instancio\n",
    "tfidf_matrix = tfidf.fit_transform(data_filtrada['texto_combinado'])  #vectorizo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizo los datos numericos a usar:\n",
    "scaler = StandardScaler()  #Instancio \n",
    "data_filtrada[['popularity','release_year']] = scaler.fit_transform(data_filtrada[['popularity', 'release_year']]) #escalo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo una matrix total uniendo las catacteristicas categóricas más las numéricas.\n",
    "matrix_total = np.hstack((tfidf_matrix.toarray(), data_filtrada[['popularity', 'release_year']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convierto tfidf_matrix a array y obtengo los valores de las columnas numéricas\n",
    "tfidf_array = tfidf_matrix.toarray()\n",
    "numeric_data = data_filtrada[['popularity', 'release_year']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura el número de componentes principales (puedes ajustar esto según sea necesario)\n",
    "n_components = 50  # Ajusta según tu caso específico\n",
    "\n",
    "# Aplica PCA para reducir la dimensionalidad\n",
    "pca = PCA(n_components=n_components)\n",
    "matrix_reduced = pca.fit_transform(matrix_total)\n",
    "\n",
    "# Calcula la matriz de similitud con la matriz reducida\n",
    "similarity_matrix = cosine_similarity(matrix_reduced, matrix_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion(titulo: str):\n",
    "    try:\n",
    "        idx_list = data_filtrada.index[data_filtrada['title'] == titulo].tolist()\n",
    "        \n",
    "        if not idx_list:\n",
    "            return {'error': \"Película no encontrada\"}\n",
    "        \n",
    "        idx = idx_list[0]\n",
    "        \n",
    "        print('Titulo de la Película:', titulo)  # Log de depuración\n",
    "        print('Índice:', idx)  # Log de depuración\n",
    "        print('Tipo de índice:', type(idx))\n",
    "\n",
    "        # Obtengo los pares de películas índice y score\n",
    "        similarity_score = list(enumerate(similarity_matrix[idx]))\n",
    "\n",
    "        # Ordeno las películas por puntaje de similitud\n",
    "        similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Tomo los índices de las 5 películas similares. Quito la primera [0] que es la misma dada\n",
    "        similar_movies_indices = [i[0] for i in similarity_score[1:6]]\n",
    "\n",
    "        recomendadas = data_filtrada['title'].iloc[similar_movies_indices].tolist()\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {'error': f\"Error interno: {str(e)}\"}\n",
    "    \n",
    "    return {'Recomendaciones': recomendadas}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_filtrada['title'].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pelicula = 'two friends'\n",
    "recomendacion(pelicula)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
